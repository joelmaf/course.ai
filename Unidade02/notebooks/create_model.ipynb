{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "651ead5b-6190-405b-a1ef-2241f567a72b",
   "metadata": {},
   "source": [
    "# UNIDADE 2: Tratamento dos dados\n",
    "\n",
    "2.1. Análise exploratória de dados (EDA)</br>\n",
    "2.2. Limpeza de dados</br>\n",
    "2.3. Transformação de dados</br>\n",
    "2.3.1. Divisão dos dados</br>\n",
    "2.3.2. Balanceamento</br>\n",
    "2.3.3. Escalonamento</br>\n",
    "2.3.4. Codificação e criação de features</br>\n",
    "2.4. Redução de dimensionalidade</br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53751408-1192-42ff-b642-907f33b69077",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid #00008B; padding: 15px; border-radius: 10px; background-color: #00008B; color: #FFFFFF; font-family: Arial;\">\n",
    "  <h1 style=\"margin-top: 0;\">Planejamento de Sucessão</h1>\n",
    "  <p>Descrição: Identificar funcionários com potencial para ocupar cargos de liderança no futuro e planejar a sucessão de cargos críticos</p>\n",
    "  <p>Dados sintéticos produzidos pelo ChatGPT, baseado no projeto Google Oxygen: Como a Google usou dados para ver se os gerentes fazem diferença?</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad91690-8c11-4df3-b8bc-bbe517e465b3",
   "metadata": {},
   "source": [
    "\n",
    "- https://www.linkedin.com/pulse/project-oxygen-8-conselhos-do-google-para-o-gerente-david/</br>\n",
    "- https://www.feedz.com.br/blog/projeto-oxigenio-do-google</br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55c4ca1-1a08-4847-83fd-3c9ee57b42cc",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color: #f0f8ff; padding: 20px; border-radius: 10px;\">\n",
    "  <ul>\n",
    "    <li>Idade do funcionário (valores inteiros  de 18 a 75)</li>\n",
    "    <li>Nível de educação (valores Superior, Médio, Doutorado, Especialização)</li>\n",
    "    <li>Avaliação de desempenho (valores inteiros  entre 0 e 5)</li>\n",
    "    <li>Experiência em cargos de liderança(valores 0 ou 1)</li>\n",
    "    <li>Habilidades e competências (valores inteiros entre 0 a 10)</li>\n",
    "    <li>Participação em treinamentos de liderança (valores S ou N)</li>\n",
    "    <li>Feedback de supervisores (valores reais enter 0.0 e 1.0)</li>\n",
    "    <li>Satisfação no trabalho (valores inteiros entre 0 e 5)</li>\n",
    "    <li>É um bom coach (valores S ou N)</li>\n",
    "    <li>Empodera a equipe e não faz microgestão (valores S ou N)</li> \n",
    "    <li>Exprime interesse e preocupação pelo sucesso e bem-estar pessoal dos membros da equipe (valores S ou N)</li>\n",
    "    <li>É produtivo e orientado para os resultados (valores S ou N)</li>\n",
    "    <li>É bom comunicador - escuta e compartilha informações (valores S ou N)</li>\n",
    "    <li>Ajuda com desenvolvimento de carreira (valores S ou N)</li>\n",
    "    <li>Tem uma visão clara e estratégia para a equipe (valores S ou N)</li>\n",
    "    <li>Possui habilidades técnicas fundamentais que o ajudam a aconselhar a equipe (valores S ou N)</li>\n",
    "    <li><b>Lider (valores S ou N)</b></li>\n",
    "  </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a7f61e-e105-4a32-b5c8-0bcb6adab90b",
   "metadata": {},
   "source": [
    "# Classificação Binária\n",
    "\n",
    "A classificação em uma de duas classes é um problema comum em aprendizado de máquina. Você pode querer prever se um cliente provavelmente fará uma compra ou não, se uma transação de cartão de crédito foi fraudulenta ou não. Todos esses são problemas de classificação binária.\n",
    "\n",
    "Nos seus dados brutos, as classes podem ser representadas por strings como \"Sim\" e \"Não\". Antes de usar esses dados, atribuiremos um rótulo de classe: uma classe será 0 e a outra será 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b420849c-4c37-4945-8245-6837eaa8d406",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f0f8ff; padding: 20px; border-radius: 10px;\">\n",
    "  <h3>Fluxo no Pipeline</h3>\n",
    "  <ul>\n",
    "    <li><b>Ingestão de Dados</b>: Coleta e armazenamento de dados brutos.</li>\n",
    "    <li><b>Análise Exploratória</b>: Utilização dos dados para EDA.</li>\n",
    "    <li><b>Pré-processamento</b>: Limpeza e transformação dos dados.</li>\n",
    "    <li><b>Normalização e Engenharia de Features</b>: Criação de datasets normalizados e finalizados para treinamento.</li>\n",
    "    <li><b><span style=\"color:red\">Treinamento de Modelos</b>: Utilização dos dados de treinamento e validação para treinar e validar modelos.</span></li>\n",
    "    <li><b>Implantação de Modelos</b>: Armazenamento dos modelos treinados em um Model Registry.</li>\n",
    "    <li><b>Inferência</b>: Utilização de dados de inferência para obter predições dos modelos em produção.</li>\n",
    "  </ul>\n",
    "\n",
    "Considerações de MLOps\n",
    "\n",
    "  <ul>\n",
    "    <li><b>Versionamento</b>: Versionar tanto os dados quanto os modelos para garantir a reprodutibilidade.</li>\n",
    "    <li><b>Monitoramento</b>: Implementar monitoramento contínuo dos modelos em produção para detectar drifts de desempenho.</li>\n",
    "    <li><b>Automatização</b>: Automatizar o pipeline de dados e modelos utilizando ferramentas de CI/CD.</li>\n",
    "    <li><b>Segurança</b>: Garantir a segurança e conformidade dos dados, especialmente se envolver dados sensíveis.</li>\n",
    "  </ul>\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36bdde9-602e-4787-984c-6ee345e01561",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd836fa-45d2-4f00-8ac0-1bc7b6ba3fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import joblib\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b2fd11-b078-4353-9159-c3c023958486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3673bbaa-c270-4577-bcda-e7c99e09fcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalizado = pd.read_csv(\"../data/processed/sucessao_normalizado.csv\")\n",
    "df_servidor = pd.read_csv(\"../data/interim/sucessao_processado.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e20cea1-3e00-4880-b08e-0a28f087ed2f",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f0f8ff; padding: 20px; border-radius: 10px;\">\n",
    "<h3> Divisão em treino e teste</h3>\n",
    "\n",
    "Em aprendizado de máquina, é fundamental dividir o conjunto de dados em partes de treino e teste para avaliar de forma eficaz o desempenho de um modelo.\n",
    "\n",
    "1. <b>Avaliação do Desempenho</b>\n",
    "Dividir os dados em treino e teste permite uma avaliação objetiva do modelo. O conjunto de treino é utilizado para ajustar o modelo, enquanto o conjunto de teste, que o modelo não viu durante o treinamento, serve para avaliar a capacidade de generalização do modelo. \n",
    "\n",
    "2. <b>Prevenção do Overfitting</b>\n",
    "O overfitting ocorre quando um modelo se ajusta excessivamente aos dados de treinamento, capturando ruídos e padrões específicos dos dados de treino que não se generalizam para novos dados. Dividir os dados em treino e teste ajuda a identificar e mitigar o overfitting, pois um modelo que se sai bem no conjunto de treino, mas mal no conjunto de teste, é provavelmente um modelo superajustado.\n",
    "\n",
    "3. <b>Estimativa Realista de Desempenho</b>\n",
    "Treinar e testar o modelo nos mesmos dados pode levar a uma estimativa irrealisticamente alta de desempenho, pois o modelo pode simplesmente memorizar os dados de treino. Ao separar um conjunto de teste, obtemos uma estimativa mais realista de como o modelo se comportará em situações do mundo real, onde ele encontrará dados não vistos.\n",
    "\n",
    "4. <b>Ajuste de Hiperparâmetros</b>\n",
    "A divisão entre treino e teste é também útil para ajustar os hiperparâmetros do modelo. Os hiperparâmetros são parâmetros que não são aprendidos pelo modelo durante o treinamento e precisam ser definidos antes do treinamento. Utilizando uma parte dos dados para validação (um conjunto separado ou através de validação cruzada), podemos ajustar esses hiperparâmetros para otimizar o desempenho do modelo no conjunto de teste.\n",
    "\n",
    "5. <b>Garantia de Robustez</b>\n",
    "Testar o modelo em dados não vistos fornece uma medida de robustez do modelo. Um modelo robusto é aquele que mantém seu desempenho mesmo quando exposto a diferentes conjuntos de dados. Dividir os dados ajuda a garantir que o modelo seja robusto e possa generalizar bem para novos dados.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110440bb-24c5-4b35-86f8-897207a14e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_normalizado.loc[:, df_normalizado.columns != 'Lider']\n",
    "y = df_normalizado[\"Lider\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "###X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e95fcf-a1ec-4a17-a62a-270c3fb542f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('../data/train/X_train.csv', index=False)\n",
    "X_test.to_csv('../data/train/X_test.csv', index=False)\n",
    "\n",
    "y_train.to_csv('../data/train/y_train.csv', index=False)\n",
    "y_test.to_csv('../data/train/y_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404d1a3c-d75b-4ae4-8a23-210fe8351f44",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ffcccc; padding: 20px; border-radius: 10px;\">\n",
    "<h3>Desbalanceamento de dados</h3>\n",
    "\n",
    "Treinar um modelo de classificação com variáveis desbalanceadas pode resultar em problemas, pois a classe dominante tende a se sobressair, dificultando a previsão da classe minoritária. Datasets onde mais de 50% das entradas pertencem a uma única classe são considerados desbalanceados. Isso afeta o desempenho dos algoritmos de aprendizado de máquina, que preferem dados equilibrados para otimizar a precisão. Em dados desbalanceados, os algoritmos tendem a favorecer a classe majoritária, resultando em classificações incorretas da classe minoritária.\n",
    "\n",
    "Neste processo, tanto X_train quanto y_train são ajustados de forma que a quantidade de exemplos em cada classe da variável alvo (y_train) seja equilibrada, e as respectivas características (X_train) sejam mantidas.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef1f0b2-43f5-488a-8e34-85fd6aaedc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "count1 = X_train[\"Experiencia_cargos_lideranca\"].value_counts().reset_index()\n",
    "count1.columns = ['Experiencia_cargos_lideranca', 'Contagem']\n",
    "\n",
    "count2 = y_train.value_counts().reset_index()\n",
    "count2.columns = ['Lider', 'Contagem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9852d2-f13e-423b-b2cf-23f52b1b60cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "count1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53371e5e-8d2a-4560-856d-e3ec6ab3b5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "count2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355b14f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "sns.barplot(data=count1, x='Experiencia_cargos_lideranca', y='Contagem', palette='viridis', ax=axes[0])\n",
    "axes[0].set_title('Distribuição Experiencia em cargos de liderança')\n",
    "axes[0].set_xlabel('Experiencia em cargos de liderança')\n",
    "axes[0].set_ylabel('Contagem')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "sns.barplot(data=count2, x='Lider', y='Contagem', palette='viridis', ax=axes[1])\n",
    "axes[1].set_title('Distribuição da Liderança')\n",
    "axes[1].set_xlabel('Lider')\n",
    "axes[1].set_ylabel('Contagem')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed2ecdf-e312-44d2-ada7-43c7dd0a19c0",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ffcccc; padding: 20px; border-radius: 10px;\">\n",
    "<b>Undersampling</b> envolve <b>reduzir a quantidade de dados da classe majoritária</b> para igualar a classe minoritária, equilibrando as observações.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48b0dec-cdb0-479b-9430-53c1ca797ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(sampling_strategy = 'majority')\n",
    "X_resampled_under, y_resampled_under = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bdc7fe-297f-4cbc-b18a-17a856ee621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "count1 = X_resampled_under[\"Experiencia_cargos_lideranca\"].value_counts().reset_index()\n",
    "count1.columns = ['Experiencia_cargos_lideranca', 'Contagem']\n",
    "\n",
    "count2 = y_resampled_under.value_counts().reset_index()\n",
    "count2.columns = ['Lider', 'Contagem']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf42517-bef6-48c8-ba49-d41ae4a03bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuste das FEATURES para equilibrar a TARGET\n",
    "count1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d59e14-6991-4d1f-8fba-d21a035670a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A variável TARGET fica equilibrada\n",
    "count2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9999b60-eda7-4277-b42f-9a64fe4fd67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "sns.barplot(data=count1, x='Experiencia_cargos_lideranca', y='Contagem', palette='viridis', ax=axes[0])\n",
    "axes[0].set_title('Distribuição Experiencia em cargos de liderança')\n",
    "axes[0].set_xlabel('Experiencia em cargos de liderança')\n",
    "axes[0].set_ylabel('Contagem')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "sns.barplot(data=count2, x='Lider', y='Contagem', palette='viridis', ax=axes[1])\n",
    "axes[1].set_title('Distribuição da Liderança')\n",
    "axes[1].set_xlabel('Lider')\n",
    "axes[1].set_ylabel('Contagem')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6d2c85-cd09-4b8d-bbed-5bfe8c7b93d3",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ffcccc; padding: 20px; border-radius: 10px;\">\n",
    "<b>Oversampling</b> <b>aumenta a quantidade de registros da classe minoritária</b>, podendo duplicar registros aleatoriamente, embora isso possa gerar muitas informações idênticas. Para evitar duplicações, pode-se usar a técnica SMOTE, que cria novos dados sintéticos semelhantes aos dados reais, mas não idênticos. O SMOTE é projetado para gerar novos exemplos sintéticos interpolando entre os existentes, o que pode resultar em valores contínuos. </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c880024f-ce81-4a17-9943-d17bf8c44385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar as bibliotecas necessárias\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "X_resampled_Over, y_resampled_Over = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec270a4c-ecf2-4f1d-8167-faeedce2158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "count1 = X_resampled_Over[\"Experiencia_cargos_lideranca\"].value_counts().reset_index()\n",
    "count1.columns = ['Experiencia_cargos_lideranca', 'Contagem']\n",
    "\n",
    "count2 = y_resampled_Over.value_counts().reset_index()\n",
    "count2.columns = ['Lider', 'Contagem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0b2785-9491-456e-9f39-8697241231bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "count1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14440c4e-0243-4acc-b49e-4d26d3ae3098",
   "metadata": {},
   "outputs": [],
   "source": [
    "count2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c25051-f964-4a16-a898-efbdbe750654",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "sns.barplot(data=count1, x='Experiencia_cargos_lideranca', y='Contagem', palette='viridis', ax=axes[0])\n",
    "axes[0].set_title('Distribuição Experiencia em cargos de liderança')\n",
    "axes[0].set_xlabel('Experiencia em cargos de liderança')\n",
    "axes[0].set_ylabel('Contagem')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "sns.barplot(data=count2, x='Lider', y='Contagem', palette='viridis', ax=axes[1])\n",
    "axes[1].set_title('Distribuição da Liderança')\n",
    "axes[1].set_xlabel('Lider')\n",
    "axes[1].set_ylabel('Contagem')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1ca45f-05e8-490b-bb3c-b1953565d61b",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ffcccc; padding: 20px; border-radius: 10px;\">\n",
    "Para <b>variáveis binárias</b>, é mais adequado usar <b>outras técnicas de oversampling</b>, como a duplicação aleatória de amostras da classe minoritária.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07829967-e95c-4bf2-8580-2163e5137ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "data = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# Separar as classes majoritária e minoritária\n",
    "majority_class = data[data[y_train.name] == 0]\n",
    "minority_class = data[data[y_train.name] == 1]\n",
    "\n",
    "# Oversample da classe minoritária\n",
    "minority_oversampled = resample(minority_class, \n",
    "                                replace=True,  \n",
    "                                n_samples=len(majority_class),\n",
    "                                random_state=42)   \n",
    "\n",
    "# Combinar as classes majoritária e minoritária reamostrada\n",
    "data_resampled = pd.concat([majority_class, minority_oversampled])\n",
    "\n",
    "X_resampled_Over = data_resampled.drop(columns=[y_train.name])\n",
    "y_resampled_Over = data_resampled[y_train.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a0c39b-037e-498a-8498-ae19eeea7c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled_Over[\"Experiencia_cargos_lideranca\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dea4438-d29d-434c-85d9-79af7b7d8cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_resampled_Over.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1a920f-4893-4038-9fdd-fafe7059f3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "count1 = X_resampled_Over[\"Experiencia_cargos_lideranca\"].value_counts().reset_index()\n",
    "count1.columns = ['Experiencia_cargos_lideranca', 'Contagem']\n",
    "\n",
    "count2 = y_resampled_Over.value_counts().reset_index()\n",
    "count2.columns = ['Lider', 'Contagem']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "sns.barplot(data=count1, x='Experiencia_cargos_lideranca', y='Contagem', palette='viridis', ax=axes[0])\n",
    "axes[0].set_title('Distribuição Experiencia em cargos de liderança')\n",
    "axes[0].set_xlabel('Experiencia em cargos de liderança')\n",
    "axes[0].set_ylabel('Contagem')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "sns.barplot(data=count2, x='Lider', y='Contagem', palette='viridis', ax=axes[1])\n",
    "axes[1].set_title('Distribuição da Liderança')\n",
    "axes[1].set_xlabel('Lider')\n",
    "axes[1].set_ylabel('Contagem')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24978806-b58e-4341-819d-ccd4554a24cb",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f0f8ff; padding: 20px; border-radius: 10px;\">\n",
    "<h3>A Função Pipeline</h3>\n",
    "A função Pipeline do módulo sklearn.pipeline no Python é usada para montar uma sequência de transformações e um estimador final em um único objeto. Essa abordagem é útil para garantir que as transformações necessárias nos dados sejam aplicadas de forma consistente antes do treinamento do modelo, bem como durante a previsão. Além disso, a Pipeline facilita o uso de técnicas de validação cruzada e a otimização de hiperparâmetros. para node hiperparâmetros.</br></br>\n",
    "\n",
    "<b>Crie as etapas a serem executadas, crie a pipeline e execute</b></br>\n",
    "steps = [('scale', StandardScaler()), ('LR', LinearRegression())]</br>\n",
    "pipe = Pipeline(steps)</br>\n",
    "pipe.fit(X,y)</br>\n",
    "  \n",
    "</div>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57eb69e-ad15-44fd-a746-de88882959b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lr=Pipeline([('model_lr',LogisticRegression(random_state=42))])\n",
    "pipeline_dt=Pipeline([('model_dt',DecisionTreeClassifier(random_state=42))])\n",
    "pipeline_rf=Pipeline([('model_rf',RandomForestClassifier())])\n",
    "\n",
    "pipelines = [pipeline_lr, pipeline_dt, pipeline_rf]\n",
    "pipelines_dict = {0: 'LogisticRegression', 1: 'DecisionTree', 2: 'RandomForest'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362c7017-1a85-45b5-a160-8f443d02472c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pipe in pipelines:\n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "accuracy = []\n",
    "for i, model in enumerate(pipelines):\n",
    "    scores = cross_val_score(model, X_train,y_train, cv=10)\n",
    "    accuracy.append(scores)\n",
    "    print(\"%s: %f \" % (pipelines_dict[i], scores.mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8b1d4a-4fea-405d-b119-fff84a001af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(pipelines[2], f'../models/model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9838dbb-4244-4f1e-b90a-c26a677c8c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run ../app_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43073b67-7a04-4f36-8758-3e8c6666c088",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ff87b2; padding: 20px; border-radius: 10px;\">\n",
    "<h3>Atividade 2:</h3>\n",
    "\n",
    "Para o estudo de caso do Planejamento de Sucessão cujo objetivo é identificar funcionários com potencial para ocupar cargos de liderança no futuro e planejar a sucessão de cargos críticos. Atualize o código feito em sala:\n",
    "\n",
    "<ul>\n",
    "    <li> Execute a Pipeline sem usar os dados normalizados. Avalie o resultado de acurácia</li>\n",
    "    <li> Usando os dados normalizados teste o desbalanceamento de dados usando Undersampling e Oversampling. Execute a Pipeline e avalie o resultado de acurácia</li>\n",
    "        \n",
    "</ul>\n",
    "\n",
    "Poste no AVA o Jupyter Notebook ou o link para o repositório GitHub\n",
    "  \n",
    "</div>.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
