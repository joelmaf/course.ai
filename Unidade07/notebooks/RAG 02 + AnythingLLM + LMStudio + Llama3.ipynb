{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "163283ed",
   "metadata": {},
   "source": [
    "# LLM (local) framework e chatbot application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dc2a2d",
   "metadata": {},
   "source": [
    "*  Ollama (https://github.com/ollama/ollama) + Llama3\n",
    "*  Jan (https://jan.ai) + Lllama3\n",
    "*  LMStudio (https://lmstudio.ai/) + Llama3\n",
    "\n",
    "\n",
    "Outros frameworks de inferência populares llama.cpp, lamafile, GPT4All, Groq.\n",
    "\n",
    "\n",
    "https://www.datacamp.com/tutorial/run-llms-locally-tutorial\n",
    "\n",
    "https://www.infoworld.com/article/2338922/5-easy-ways-to-run-an-llm-locally.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c768a8e",
   "metadata": {},
   "source": [
    "# Instalação e Configuração do Ambiente \n",
    "### AnythingLLM + LMStudio + Llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79265889",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d66187",
   "metadata": {},
   "source": [
    "## Instalando o LMStudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a5b550",
   "metadata": {},
   "source": [
    "LM Studio é uma ferramenta de software que permite baixar e executar LLMs diretamente no computador, sem a necessidade de conexão com a internet ou acesso a infraestrutura em nuvem.O aplicativo permite acesso ao catálogo da Hugging Face, possibilitando o download dos parâmetros dos principais LLMs disponíveis, como LLaMa, Mistral, Phi 2, entre outros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5e88d3",
   "metadata": {},
   "source": [
    "### Passo 1: \n",
    "\n",
    "Faça download do LMStudio no link https://lmstudio.ai/. Escolhendo o ambiente que deseja usar. Nas aulas todos os exemplos rodarão no Linux Mint, com instalação do Linux **\"LM Studio for Linux (Beta)\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bef6db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../images/fig01.png\" width=\"800\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"../images/fig01.png\", width=800, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69e86f8",
   "metadata": {},
   "source": [
    "Observação: recomendações de hardware/software mínimos\n",
    "\n",
    "*  Apple Silicon Mac (M1/M2/M3) com macOS 13.6 ou mais recente\n",
    "*  Windows / Linux PC ou mais recente que suporta AVX2 (tipicamente novos PCs)\n",
    "*  16GB+ de RAM é recomendado. Para PCs, 6GB+ de VRAM é recomendado\n",
    "*  Suporte a GPUs:  NVIDIA/AMD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f956647c",
   "metadata": {},
   "source": [
    "### Passo 2: \n",
    "\n",
    "Depois de instalado na Home do LMStudio faça download do modelo LLM que deseja usar na sua aplicação. Nas aulas usaremos o **Llama 3 - 8B Instruct**, para instalar basta cricar em **Download**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "847ce27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../images/fig02.png\" width=\"800\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"../images/fig02.png\", width=800, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887e8a59",
   "metadata": {},
   "source": [
    "### Passo 3: \n",
    "\n",
    "No menu a esquerda escolha a opção **Local Server**. Depois em **Select a model to load** escolha o modelo que quer carregar no servidor. Nos exemplos de sala usaremos o \"Llama 3 - 8B Instruct\" que foi carregado no Passo 2.\n",
    "\n",
    "Se quiser ter certeza que tudo funcionou, pare o servidor **Stop Server** e reinicie novamente **Start Server**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf4906cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../images/fig03.png\" width=\"800\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"../images/fig03.png\", width=800, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e611afa2",
   "metadata": {},
   "source": [
    "## Instalando o Anything LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e433d1",
   "metadata": {},
   "source": [
    "AnythingLLM é uma aplicação que permite executar localmente modelos de linguagem de grande porte (LLMs) e aprimorar suas capacidades com diversos recursos. Ele atua como uma ponte entre o LLM e recursos externos. O AnythingLLM é executado inteiramente em sua máquina local ou rede, garantindo privacidade e segurança dos dados.É um projeto de código aberto, permitindo que você personalize e estenda sua funcionalidade conforme necessário."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ad60b1",
   "metadata": {},
   "source": [
    "### Passo 1: \n",
    "\n",
    "Faça download do Anything LLM no link https://anythingllm.com/download. Escolhendo o ambiente que deseja usar. Nas aulas todos os exemplos rodarão no Linux Mint, com instalação do Linux "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88b689a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../images/fig04.png\" width=\"800\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"../images/fig04.png\", width=800, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bde8065",
   "metadata": {},
   "source": [
    "### Passo 2: \n",
    "\n",
    "Depois de instalado, no menu inferior escolha o botão **Open settings** para configurar o qual LLM, VectorDB, Embeddings e outras configurações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff43a869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../images/fig12.png\" width=\"800\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"../images/fig12.png\", width=800, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84823904",
   "metadata": {},
   "source": [
    "### Passo 3: \n",
    "\n",
    "A primeira opção é configurar o acesso ao servidor onde o modelo LLM está sendo executado. Observe que o LMStudio já estará configurado. Caso não esteja configure conforme os dados da sua máquina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15ecd367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../images/fig13.png\" width=\"800\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"../images/fig13.png\", width=800, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38dbde8",
   "metadata": {},
   "source": [
    "### Passo 4: \n",
    "\n",
    "Por questões didáticas, para facilitar a configuração do ambiente, não alteraremos as opções de Vector Database, Embedder e Text Splitter e Chunking. Ficando configuras as seguintes opções repectivamente: LanceDB, AnythingLLMEmbedder, Text Chunk Size e Overlap (1000, 20)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c142043",
   "metadata": {},
   "source": [
    "### Passo 5: \n",
    "\n",
    "Para poder usar a API em uma aplicação externa é preciso criar uma API Key. Escolha a opção **Developer API** e escolhendo o botão **Generate API Key** gere uma chave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34d0f577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../images/fig14.png\" width=\"800\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"../images/fig14.png\", width=800, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9592eb2b",
   "metadata": {},
   "source": [
    "### Passo 6: \n",
    "\n",
    "Depois de configurado, volte para a tela principal (seta de retorno no menu inferior) e crie uma nova workspace clicando em **Mew Workspace**, dê um nome ao ser espaço de trabalho. Nas aulas o nome usado será \"course.ai\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c463e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../images/fig05.png\" width=\"800\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"../images/fig05.png\", width=800, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83154f6",
   "metadata": {},
   "source": [
    "### Passo 7: \n",
    "\n",
    "O próximo passo é baixar para dentro da workspace os dados que serão usados como contexto para o modelo. Para isso selecione o **botão com uma seta para cima** ao lado no nome da workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3303ae5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../images/fig06.png\" width=\"800\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"../images/fig06.png\", width=800, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31998a4",
   "metadata": {},
   "source": [
    "### Passo 8: \n",
    "\n",
    "Na próxima tela faça upload do arquivo onde está o contexto que deseja usar para montar o contexto de busca do sistema **Click to upload or drag and drop**. Nas aulas será usada a Cartilha da Justiça Comunitária do TJDFT (https://www.tjdft.jus.br/informacoes/cidadania/justica-comunitaria/publicacoes/arquivos/Cartilha_JusCom.pdf) que já foi previamente tratada e armazenda em formato txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1368f621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../images/fig07.png\" width=\"800\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"../images/fig07.png\", width=800, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cba2376",
   "metadata": {},
   "source": [
    "### Passo 9: \n",
    "\n",
    "Depois de carregado selecione o arquivo e mova para a workspace **Move to Workspace**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8693bb15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../images/fig08.png\" width=\"800\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"../images/fig08.png\", width=800, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95878c0f",
   "metadata": {},
   "source": [
    "### Passo 10: \n",
    "\n",
    "O próximo passo é gerar os embedding dos dados, para isso selecione o botão **Save and Embed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01f02b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../images/fig09.png\" width=\"800\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"../images/fig09.png\", width=800, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2824b28d",
   "metadata": {},
   "source": [
    "### Passo 11: \n",
    "\n",
    "O próximo passo é configurar a workspace. Para isso selecione o **botão com uma engrenagem** ao lado no nome da workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74fea5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../images/fig10.png\" width=\"800\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"../images/fig10.png\", width=800, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948e2084",
   "metadata": {},
   "source": [
    "### Passo 12: \n",
    "\n",
    "Na tela de configuração escolha **Chat Settings** e em **Prompt** coloque o prompt que conterá as instruções para o modelo, em **Query mode refusal response** o que deverá ser respondido se nenhuma informação relevante for encontrada e em **LLM Temperature** ajuste a temperatura para deixar o nível de criatividade do modelo reduzida. Clique no botão **Update Workspace**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b836a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../images/fig11.png\" width=\"1000\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"../images/fig11.png\", width=1000, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17bca62",
   "metadata": {},
   "source": [
    "## Testando a comunicação AnythingLLM + LMStudio + Llama3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71b738e",
   "metadata": {},
   "source": [
    "### Passo 1: \n",
    "\n",
    "Abra novamente **Open Settings** no menu inferior. Escolha a opção **Developer API**, copie a API KEY em um editor de texto qualquer e depois selecione o link **Read the API documentation**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "439560da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../images/fig21.png\" width=\"1000\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"../images/fig21.png\", width=1000, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fe2ac6",
   "metadata": {},
   "source": [
    "### Passo 2: \n",
    "\n",
    "Clique no botão **Authorize** insira a API KEY e depois **Authorize** novamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5234d2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../images/fig15.png\" width=\"500\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"../images/fig15.png\", width=500, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6338539e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../images/fig16.png\" width=\"600\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"../images/fig16.png\", width=600, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796dabc2",
   "metadata": {},
   "source": [
    "### Passo 3: \n",
    "\n",
    "Encontre o endpoint **POST**, **/v1/workspace/{slug}/chat** abra e clique em **Try it out**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6936a2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../images/fig18.png\" width=\"600\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"../images/fig18.png\", width=600, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bddb17",
   "metadata": {},
   "source": [
    "### Passo 4: \n",
    "\n",
    "Em **slug** coloque o nome do seu workspace e em **Request body** alguma pergunta que possa ser respondida com base no arquivo que você fez upload e está armazenado no VectorDB. **Execute**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b897f326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../images/fig19.png\" width=\"600\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"../images/fig19.png\", width=600, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532a486f",
   "metadata": {},
   "source": [
    "### Final: \n",
    "\n",
    "Se tudo der certo você verá em **Request URL** a url de requisição, em **Server Response** a resposta montada pelo RAG, especificamente o campo **textResponse**, mas também verá os contextos que foram entregues ao RAG com as respectivas similaridades e outros metadados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3af5f949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../images/fig20.png\" width=\"600\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"../images/fig20.png\", width=600, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a7d556",
   "metadata": {},
   "source": [
    "# Mais referências: como rodar LLM localmente e em produção"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1754983b",
   "metadata": {},
   "source": [
    "Executar LLMs em um ambiente de produção requer uma consideração cuidadosa de fatores como escalabilidade, confiabilidade e relação custo-benefício.\n",
    "\n",
    "*  PPLX API\n",
    "*  Cloudflare\n",
    "*  Replicate\n",
    "\n",
    "https://klu.ai/blog/open-source-llm-models#local\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
