{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "172a8e50-0de1-4af5-a17c-513b795304d1",
   "metadata": {},
   "source": [
    "# UNIDADE 3:  Regressão Linear\n",
    "\n",
    "3.1 Previsões simples (Regressão linear)\n",
    "\n",
    "3.2 Previsões complexas (Regressão linear múltipla)\n",
    "\n",
    "3.3   Algoritmos de Classificação\n",
    "\n",
    "3.3.1 Métodos simbólicos: Árvore de Decisão\n",
    "\n",
    "3.3.2 Métodos ensemble: Random Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4add8ee8-ccb8-4b01-a637-4d39e13210e9",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid #00008B; padding: 15px; border-radius: 10px; background-color: #00008B; color: #FFFFFF; font-family: Arial;\">\n",
    "  <h1 style=\"margin-top: 0;\"> Predição de Cargas de Trabalho para Juízes</h1>\n",
    "  <p>Descrição: Prever o volume de trabalho em diferentes tribunais com base em fatores como tamanho da população, tipos de casos comuns na região, etc.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b32c809-065d-4a3a-89c6-3ba080772535",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color: #f0f8ff; padding: 20px; border-radius: 10px;\">\n",
    "  <ul>\n",
    "    <li>Tamanho da população da região onde o tribunal está localizado (valores real entre 30,000 e 500,000)</li>\n",
    "    <li>Número de juízes ativos no tribunal (valores inteiros entre 1 e 20)</li>\n",
    "    <li>Número de casos recebidos mensalmente (valores inteiros entre 150 e 800)</li>\n",
    "    <li>Distribuição dos tipos de casos comuns na região (valores: criminal, civil, trabalhista)</li>\n",
    "    <li>Taxa de crescimento da população na região (valores reais entre 0.0 e 1.0)</li>\n",
    "    <li>Taxa de criminalidade na região (valores reais entre 0.0 e 1.0)</li>\n",
    "    <li>Média de tempo gasto em cada tipo de caso em meses (número inteiro)</li>\n",
    "    <li>Nível de automação e eficiência do tribunal (valores inteiros entre 0 e 10)</li>\n",
    "    <li>Nível de congestionamento do sistema judicial na região (baixo, médio, alto)</li>\n",
    "    <li>Número de advogados atuando na região (valores inteiros entre 1 e 100)</li>\n",
    "    <li>Número de prédios judiciais na região (valores inteiros entre 1 e 10)</li>\n",
    "    <li>Nível de urbanização da região (baixo, médio, alto)</li>\n",
    "    <li>Nível de educação da população na região (valores reais entre 0.0 e 1.0)</li>\n",
    "    <li>Número de habitantes por juiz (valor fruto da divisão de tamanho da população da região pelo número de juízes ativos no tribunal)</li>\n",
    "    <li>Índice de Desenvolvimento Humano (valores reais entre 0.0 e 1.0)</li>\n",
    "    <li>Média de idade dos  es (entre 35 e 60)</li>\n",
    "    <li><b>Número de casos pendentes atualmente no tribunal (valores inteiros, coluna que não pode ser nula)</b></li>\n",
    "  </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075e24e7-d333-475a-8412-393091e850c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fabe743-02dd-4e24-abb6-5564c623678b",
   "metadata": {
    "id": "d36cbb02-d052-43eb-9157-98be9029c25b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.float_format', '{:.5f}'.format)\n",
    "\n",
    "import streamlit as st\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a156bde2-4dd3-400f-8e3a-993330f5c010",
   "metadata": {
    "id": "a156bde2-4dd3-400f-8e3a-993330f5c010"
   },
   "source": [
    "# Treinando o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d81af5-43cd-4cbb-8f15-b9506c56ea4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalizado = pd.read_csv(\"../data/processed/predicao_cargas_trabalho_normalizado.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb1d344-473c-4cda-b590-04286d8dcf5d",
   "metadata": {
    "id": "8eb1d344-473c-4cda-b590-04286d8dcf5d"
   },
   "outputs": [],
   "source": [
    "X = df_normalizado.loc[:, df_normalizado.columns != 'casos_pendentes']\n",
    "y = df_normalizado[\"casos_pendentes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q-lVycA0-ndM",
   "metadata": {
    "id": "Q-lVycA0-ndM"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3513303d-836d-46df-bde5-7d583858fb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('../data/train/X_train.csv', index=False)\n",
    "X_test.to_csv('../data/train/X_test.csv', index=False)\n",
    "\n",
    "y_train.to_csv('../data/train/y_train.csv', index=False)\n",
    "y_test.to_csv('../data/train/y_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10961beb-472d-4675-8a25-1b3521a0e5e0",
   "metadata": {},
   "source": [
    "### Utilizando o modelo LinearRegression() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YPOnSKJSH6dV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YPOnSKJSH6dV",
    "outputId": "62713679-f517-412c-8b0b-e8615f5f24a4"
   },
   "outputs": [],
   "source": [
    "modelLinearRegression = LinearRegression()\n",
    "modelLinearRegression.fit(X_train,y_train)\n",
    "print('Coefficients: \\n', modelLinearRegression.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_N30Z1rEI5Pk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 708
    },
    "id": "_N30Z1rEI5Pk",
    "outputId": "a2eff938-8774-4374-d7fe-9c1f9ae05ff0"
   },
   "outputs": [],
   "source": [
    "coeffecients = pd.DataFrame(modelLinearRegression.coef_,X.columns)\n",
    "coeffecients.columns = ['Coeffecient']\n",
    "coeffecients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48552b95-04cc-4ccc-beb9-dfebf1c9f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo a previsão\n",
    "#data_new = np.array([[....]])\n",
    "#predictions_new = modelLinearRegression.predict(data_new)\n",
    "#print(predictions_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fa2d07-1360-4141-87be-1ae4ea921bc8",
   "metadata": {},
   "source": [
    "# Avaliação do Desempenho\n",
    "\n",
    "* **Erro de Treinamento vs. Erro de Validação/Teste**: Compare o erro do modelo no conjunto de treinamento com o erro nos conjuntos de validação e test.\n",
    "* **Overfitting**: Se o <b>erro</b> no conjunto de <span style=\"color:red\"><b>treinamento é muito baixo</b></span>, mas o erro no conjunto de <span style=\"color:red\"><b>validação/teste é significativamente maior</b></span>, o modelo pode estar overfitting.\n",
    "     * Muitas features confundem o modelo.\n",
    "     * Usar um modelo complexo para um problema simples.\n",
    "     * Pouca regularização.\n",
    "</br></br>\n",
    "* **Underfitting**: Se o <b>erro</b> no conjunto de <span style=\"color:red\"><b>treinamento e nos conjuntos de validação/teste é alto</b></span>, o modelo pode estar underfitting.\n",
    "     * Poucas features perdem detalhes importantes.\n",
    "     * Usar um modelo simples para um problema complexo.\n",
    "     * Excessiva regularização limita a flexibilidade do modelo.\n",
    " \n",
    "<img src=\"../img/overfitting_2.png\" width=400 />\n",
    "\n",
    "\n",
    "<img src=\"../img/overunder.png\" width=300 />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "o5SH671Svzj7",
   "metadata": {
    "id": "o5SH671Svzj7"
   },
   "source": [
    "# Métricas de avaliação: regressão\n",
    "\n",
    "https://towardsai.net/p/l/5-regression-metrics-explained-in-just-5mins\n",
    "\n",
    " As métricas abaixo são identificadas também como **funções de perda**, o objetivo é encontrar um modelo que tenha a menor função de perda.\n",
    "\n",
    "**Mean Absolute Error** (MAE): Erro Absoluto Médio é a <b>média do valor absoluto dos erros (diferenças absolutas entre os valores preditos e os valores observados)</b>.  <b>MAE é menos sensível a outliers</b> do que outras métricas como MSE, porque não eleva os erros ao quadrado. MAE é útil quando <span style=\"color:red\"><b>se quer uma métrica que seja robusta a outliers</b></span> e deseja-se entender a média absoluta dos erros em termos simples.\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n|y_i-\\hat{y}_i|$$\n",
    "\n",
    "<img src=\"../img/mae.png\" width=500 />\n",
    "\n",
    "<b>Interpretação do MAE:</b> Um MAE mais baixo indica uma maior precisão nos resultados da simulação.\n",
    "\n",
    "</br></br>\n",
    "\n",
    "**Mean Squared Error** (MSE): Erro Médio Quadrático é a <b>média dos erros quadrados, pune erros maiores</b>. MSE é preferido quando se deseja <span style=\"color:red\"><b>penalizar mais fortemente os erros maiores</b></span>, o que é comum em modelos onde grandes desvios são particularmente indesejáveis.\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$$\n",
    "\n",
    "<img src=\"../img/mse.png\" width=500 />\n",
    "\n",
    "<b>Interpretação do MSE:</b> Um valor de <b>MSE mais baixo indica uma maior precisão na previsão</b>, pois implica que as <span style=\"color:red\"><b>previsões do modelo estão mais próximas dos valores reais</b></span>. Por outro lado, um MSE mais alto sugere uma menor precisão e maiores discrepâncias entre as previsões do modelo e os valores reais.\n",
    "\n",
    "</br></br>\n",
    "\n",
    "**Root Mean Square Error** (RMSE): Raiz do Erro Quadrático Médio é a <b>raiz quadrada da média dos erros quadrados</b>. RMSE é frequentemente usado em contextos onde é importante <b>manter as unidades do erro comparáveis com os dados originais e ao mesmo tempo penalizar erros maiores</b>. O RMSE, em particular, <span style=\"color:red\"><b>nos dá uma ideia do erro médio em relação às unidades dos dados originais</b></span>. Ela é boa para acompanhar a melhoria do modelo, mas não é boa para dizer o quao bom o modelo é. Por exemplo, um RMSE de 2 significa que as predições estão longe 2 unidades da média.\n",
    "\n",
    "$$\\sqrt{\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}$$\n",
    "\n",
    "<img src=\"../img/rmse.png\" width=500 />\n",
    "\n",
    "</br></br>\n",
    "\n",
    "**Coeficiente de Determinação** (R²): O R² <b>mede a proporção da variância nos valores dependentes que é explicada pelo modelo</b>. Ele é uma medida de <span style=\"color:red\"><b>quão bem os valores preditos se ajustam aos valores reais</b></span>. O R² varia de 0 a 1 (ou pode ser negativo se o modelo for pior que uma linha horizontal). Um valor de R² de 1 indica que o modelo explica 100% da variância nos dados; um valor de 0.75 que explica 75% dos dados, um valor de 0 indica que o modelo não explica nenhuma variância em relação aos valores reais. Em geral, <span style=\"color:red\"><b>quanto mais próximo de 1, melhor o modelo se ajusta aos dados</b></span>. Um R² muito alto no treinamento, mas muito baixo no teste, pode indicar overfitting.\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}\n",
    "$$\n",
    "\n",
    "<img src=\"../img/fig5.png\" width=500 height=200/>\n",
    "<img src=\"../img/fig6.png\" width=500 height=200/>\n",
    "\n",
    "\n",
    "<img src=\"../img/fig3.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf1d3a7-0b5d-4464-abe3-1654f28436ef",
   "metadata": {},
   "source": [
    "### Sinais de Overfitting\n",
    "\n",
    "* Treino: BAIXO erro (MAE, MSE, RMSE) e ALTO R²\n",
    "* Teste: ALTO erro (MAE, MSE, RMSE) e BAIXO R²\n",
    "\n",
    "### Sinais de Underfitting\n",
    "\n",
    "* Treino: ALTO erro (MAE, MSE, RMSE) e BAIXO R²\n",
    "* Teste: ALTO erro (MAE, MSE, RMSE) e BAIXO R²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3quz1K9XIPJc",
   "metadata": {
    "id": "3quz1K9XIPJc"
   },
   "outputs": [],
   "source": [
    "predictions = modelLinearRegression.predict(X_test)\n",
    "predictions_train = modelLinearRegression.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OJ9u0S_hxa5O",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OJ9u0S_hxa5O",
    "outputId": "b6b5d232-cde1-49ff-f6c2-145a3b7443a5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print(\"Test\")\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "print('R2:', r2_score(y_test, predictions))\n",
    "\n",
    "print(\"\\nTrain\")\n",
    "print('MAE:', metrics.mean_absolute_error(y_train, predictions_train))\n",
    "print('MSE:', metrics.mean_squared_error(y_train, predictions_train))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_train, predictions_train)))\n",
    "print('R2:', r2_score(y_train, predictions_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73631df0-1d9a-4668-b667-2a2076f4f008",
   "metadata": {},
   "source": [
    "# Diagnóstico de Resíduos\n",
    "\n",
    "Analise a distribuição dos resíduos (<span style=\"color:red\"><b>diferença entre valores previstos e reais</b></span>).\n",
    "\n",
    "* **Overfitting**: Pode apresentar <b>resíduos sistematicamente distribuídos em uma direção específica ou grandes resíduos em dados de teste</b>.\n",
    "* **Underfitting**: <b>Resíduos altos e de distribuição uniforme</b> indicam que o modelo não está capturando bem a variação nos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08701ec6-3420-44f9-8a6f-3908a6f80390",
   "metadata": {},
   "source": [
    "### Histograma dos Resíduos\n",
    "\n",
    "Verificar se os resíduos seguem uma distribuição normal, que é uma suposição comum em regressão linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "I-zFb7OPIoHq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "I-zFb7OPIoHq",
    "outputId": "aa64e422-ac7c-488b-a99f-9bdc9b6c59e9"
   },
   "outputs": [],
   "source": [
    "sns.histplot((y_test-predictions),bins=50);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895b67a4-3cee-4808-b3e8-0e2494632b83",
   "metadata": {},
   "source": [
    "Os resíduos se aproximam de uma distribuição normal nos quantis mais centrais, entretanto, montra ter uma cauda, se distanciando do caso ideal, o que foi confirmado no histograma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d80a93-72ef-4ed9-acf0-a6bc76fce77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_result = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6b11d7-3925-4c5c-a1a3-b70fe71ad06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_model = {\n",
    "    'MODEL': 'LinearRegression',\n",
    "    'MAE': metrics.mean_absolute_error(y_test, predictions),\n",
    "    'MSE': metrics.mean_squared_error(y_test, predictions),\n",
    "    'RMSE': np.sqrt(metrics.mean_squared_error(y_test, predictions)),\n",
    "    'R2': r2_score(y_test, predictions)\n",
    "}\n",
    "\n",
    "models_result.append(metric_model)\n",
    "models_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaf308c-f602-4033-8c1d-18cdf4367161",
   "metadata": {},
   "source": [
    "# Salvando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba1d70a-06d0-487a-9711-a8d27e7fadc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(modelLinearRegression, '../models/model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2777f9-4f64-4e0a-89e1-2ca47b8c8ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run ../app_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5706ab6a-ab0e-45b0-b303-2fb5072140a9",
   "metadata": {},
   "source": [
    "# Testando outros modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e23b742-3dc3-498a-8564-3974c16c6aba",
   "metadata": {},
   "source": [
    "<h2>✅ Ridge</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd794da-2224-4840-87ab-26817caf82c4",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ffcccc; padding: 20px; border-radius: 10px;\">\n",
    "A regressão ridge é uma técnica de regularização usada para aumentar a robustez da regressão linear, especialmente quando há <b>multicolinearidade entre as variáveis preditoras. A regressão ridge adiciona uma <span style=\"color:red\">penalização do tipo L2 ao termo de erro da regressão linear, que é o quadrado da magnitude dos coeficientes</span>.</b>\n",
    "\n",
    "Quando há um grande número de variáveis preditoras em relação ao número de observações, o modelo linear simples pode se ajustar demais aos dados de treinamento, levando ao overfitting. A regularização L2 da regressão ridge pode ajudar a prevenir isso. <b>Se você tem um número pequeno de variáveis preditivas que não são altamente correlacionadas</b>, a regularização pode <b>não ser necessária</b> e pode até prejudicar o desempenho do modelo.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f363d65d-7fd3-49ed-8648-ca15dc1352ed",
   "metadata": {},
   "source": [
    "*  **alpha:** parâmetro de regularização que controla a força da penalização. Um alpha maior aumenta a penalização e pode levar a mais coeficientes sendo encolhidos a zero, promovendo um modelo mais esparso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efb44ae-6b11-4372-9b36-fd58c17d94ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "#modelRidge = Ridge()\n",
    "modelRidge.fit(X_train,y_train)\n",
    "\n",
    "predictions = modelRidge.predict(X_test)\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "print('R2:', r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3028b6b0-8ae8-4a7e-9351-dc6491490578",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot((y_test-predictions),bins=50);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c517300-4c9f-4c7f-82fd-a18f730d4a3f",
   "metadata": {},
   "source": [
    "<h2>✅ Lasso</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fec1012-0cbe-4abc-b1ef-381825ba7485",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ffcccc; padding: 20px; border-radius: 10px;\">\n",
    "A regressão Lasso (Least Absolute Shrinkage and Selection Operator) é uma técnica de regularização que <b>adiciona uma <span style=\"color:red\">penalização do tipo L1 ao termo de erro da regressão linear, que é a soma das magnitudes dos coeficientes</span></b>. A principal característica da regressão Lasso é sua capacidade de realizar a seleção de variáveis, tornando alguns coeficientes exatamente zero e eliminando variáveis irrelevantes.\n",
    "\n",
    "Quando você deseja um modelo que possa realizar a seleção de variáveis automaticamente, o Lasso é uma excelente escolha, pois encolhe alguns coeficientes exatamente a zero. <b>Se você tem poucas variáveis preditoras, a seleção de variáveis pode não ser necessária e a regularização L1 pode ser desnecessária</b>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a87a322-189a-4dab-bf52-2f8a773481b8",
   "metadata": {},
   "source": [
    "*  **alpha:** é o parâmetro de regularização que controla a força da penalização. Um alpha maior aumenta a penalização e pode levar a mais coeficientes sendo encolhidos a zero, promovendo um modelo mais esparso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607df030-ef08-4e9e-9d14-51f73327ddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "#modelLasso = Lasso()\n",
    "modelLasso.fit(X_train,y_train)\n",
    "\n",
    "predictions = modelLasso.predict(X_test)\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "print('R2:', r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1e59c3-e8a6-4297-904f-2e91c241c15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot((y_test-predictions),bins=50);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9facf869-a965-4564-a433-32e2adbd552e",
   "metadata": {},
   "source": [
    "<h2>✅ ElasticNet</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560f0d5c-7eef-4244-9091-8ac9cee23ddd",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ffcccc; padding: 20px; border-radius: 10px;\">\n",
    "O modelo ElasticNet é uma <b>combinação das técnicas de <span style=\"color:red\">regularização L1 (Lasso) e L2 (Ridge)</span></b>. Ele é particularmente útil quando há necessidade de selecionar variáveis e manter a estabilidade numérica.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffa0f8f-361f-490c-a245-25fd2dddb9a5",
   "metadata": {},
   "source": [
    "*  **alpha:** parâmetro de regularização que controla a força da penalização. Um alpha maior aumenta a penalização e pode levar a mais coeficientes sendo encolhidos a zero, promovendo um modelo mais esparso.\n",
    "\n",
    "*  **l1_ratio** controla a mistura entre L1 e L2.\n",
    "    *  **l1_ratio=0** corresponde a Ridge (penalização L2).\n",
    "    *  **l1_ratio=1** corresponde a Lasso (penalização L1).\n",
    "\n",
    "Valores intermediários entre 0 e 1 proporcionam uma combinação de ambas as penalizações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f0bbbe-a9a8-4c6d-9698-817579d287cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "#modelElasticNet = ElasticNet()\n",
    "modelElasticNet.fit(X_train,y_train)\n",
    "\n",
    "predictions = modelElasticNet.predict(X_test)\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "print('R2:', r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecdd04a-192a-45d3-bd7c-5ae4bea189db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot((y_test-predictions),bins=50);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea2f1b1-f362-40a1-b45f-e78d0a5f244a",
   "metadata": {},
   "source": [
    "<h2>✅ DecisionTreeRegressor</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbc1f31-141d-479a-aef0-3af898c5663b",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ffcccc; padding: 20px; border-radius: 10px;\">\n",
    "DecisionTreeRegressor é uma <b>implementação do algoritmo de árvores de decisão para problemas de regressão</b>. As árvores de decisão fazem divisões recursivas no espaço de características, dividindo os dados em subconjuntos cada vez menores até atingir um critério de parada. O critério para dividir um nó pode ser baseado em diferentes métricas de erro, como o mean squared error (MSE) ou mean absolute error (MAE).\n",
    "As árvores de decisão são propensas a overfitting, especialmente em conjuntos de dados com muito ruído. Em tais casos, <span style=\"color:red\">técnicas de ensemble como Random Forests ou Gradient Boosting podem ser mais adequadas</span>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baab2940-db28-48cb-abbe-a086f9bdce2f",
   "metadata": {},
   "source": [
    "*  **max_depth:** A profundidade máxima da árvore. Limitar a profundidade pode prevenir overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ec974c-0e5d-45a9-a38a-56c833010b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "#modelDecisionTree = DecisionTreeRegressor()\n",
    "modelDecisionTree.fit(X_train,y_train)\n",
    "\n",
    "predictions = modelDecisionTree.predict(X_test)\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "print('R2:', r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b90d14-279f-49ed-90f3-bb612777e969",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot((y_test-predictions),bins=50);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a988cd8-4597-4cab-8e02-afea552b1ac1",
   "metadata": {},
   "source": [
    "<h2>✅ RandomForestRegressor</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767f50e0-5a5a-4241-8591-9aaec1527076",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ffcccc; padding: 20px; border-radius: 10px;\">\n",
    "RandomForestRegressor é uma implementação do algoritmo de regressão <b>baseado em florestas aleatórias</b>. As florestas aleatórias são um poderoso <b>método de ensemble</b> que <span style=\"color:red\">combina múltiplas árvores de decisão para melhorar a precisão do modelo</span> e reduzir o risco de overfitting. O RandomForestRegressor constrói um grande número de árvores de decisão independentes durante o treinamento e <b>faz a média das previsões de todas as árvores para produzir uma previsão final</b>. Cada árvore é <b>treinada em um subconjunto diferente dos dados</b>, o que ajuda a reduzir a variância do modelo. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57535913-7a62-49a4-825d-d16b882ed4cd",
   "metadata": {},
   "source": [
    "*  **n_estimators:** O número de árvores na floresta. Um número maior geralmente melhora o desempenho até certo ponto, mas aumenta o tempo de treinamento.\n",
    "*  **max_depth:** A profundidade máxima das árvores. Limitar a profundidade pode ajudar a prevenir overfitting.\n",
    "*  **bootstrap:** Se verdadeiro, amostras de bootstrap são usadas ao construir árvores. Se falso, todo o conjunto de dados é usado para construir cada árvore.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f4dfbd-5c87-4e92-87e7-73025c154729",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#modelRandomForest = RandomForestRegressor()\n",
    "modelRandomForest.fit(X_train,y_train)\n",
    "\n",
    "predictions = modelRandomForest.predict(X_test)\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "print('R2:', r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08746be7-2a1f-4087-a471-c0528e1d3f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot((y_test-predictions),bins=50);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b289cdd-9a67-438e-a639-f008be96c609",
   "metadata": {},
   "source": [
    "<h2>✅ GradientBoostingRegressor</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d20a4f5-ba48-48cb-8eea-3f61f6006ede",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ffcccc; padding: 20px; border-radius: 10px;\">\n",
    "O GradientBoostingRegressor é uma implementação do algoritmo de Boosting baseado em gradiente para problemas de regressão. Combina o poder de múltiplos modelos de regressão (geralmente árvores de decisão) para formar um modelo robusto e preciso.O Gradient Boosting funciona <span style=\"color:red\"><b>adicionando iterativamente modelos fracos (geralmente árvores de decisão) para corrigir os erros dos modelos anteriores</b></span>. Ele ajusta cada novo modelo aos resíduos (diferença entre as previsões e os valores reais) dos modelos anteriores. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bec013b-1fb3-414c-b673-c45c7157d8ca",
   "metadata": {},
   "source": [
    "*  **n_estimators:** O número de árvores na floresta. Mais árvores podem aumentar a precisão até certo ponto, mas também aumentam o tempo de treinamento.\n",
    "*  **learning_rate:** Taxa de aprendizado que reduz a contribuição de cada árvore. Valores menores exigem mais árvores para um bom desempenho.\n",
    "*  **max_depth:** A profundidade máxima das árvores de decisão. Limitar a profundidade pode ajudar a prevenir overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a5f409-9ff6-41ba-bd48-aa8c59c4c63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "#modelGradientBoosting = GradientBoostingRegressor()\n",
    "modelGradientBoosting.fit(X_train,y_train)\n",
    "\n",
    "predictions = modelGradientBoosting.predict(X_test)\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "print('R2:', r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b17baa-16d5-49e3-bdba-f01765cf9450",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot((y_test-predictions),bins=50);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9044d5fb-c62b-43b9-910d-ef1f7d3b0fac",
   "metadata": {},
   "source": [
    "<h2>✅ SVR</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb6f24d-ebf1-40ed-af38-c24b44b8b9b3",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ffcccc; padding: 20px; border-radius: 10px;\">\n",
    "O SVR (Support Vector Regression) é uma implementação do algoritmo de regressão <b>baseado em máquinas de vetor de suporte (Support Vector Machines, SVM)</b>. O SVR é particularmente útil para problemas de regressão onde se deseja minimizar o erro, mas de uma maneira que permita a insensibilidade ao erro dentro de uma margem especificada (epsilon). O SVR tenta <b>encontrar uma função que tenha no máximo uma margem de erro epsilon para todos os pontos de treinamento</b>, ao mesmo tempo que tenta ser o mais plana possível.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8f4148-14db-4742-a820-e22f3f97b98e",
   "metadata": {},
   "source": [
    "*  **kernel** SVR pode usar diferentes tipos de kernels (linear, polinomial, radial basis function (RBF), sigmoid),  permitindo modelar relações não lineares. O kernel mais comum é o RBF.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe3ae67-90c0-4215-bf2b-7ad08d355045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "#modelSVR = SVR()\n",
    "modelSVR.fit(X_train,y_train)\n",
    "\n",
    "predictions = modelSVR.predict(X_test)\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "print('R2:', r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56a7b66-6e47-48c8-b4b7-f85305fdbca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot((y_test-predictions),bins=50);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59bf23b-2843-4ec6-99ac-eb76857d8927",
   "metadata": {},
   "source": [
    "<h2>✅ KNeighborsRegressor</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764536cd-9f73-4eb5-a993-4aa84fd3cec3",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ffcccc; padding: 20px; border-radius: 10px;\">\n",
    "O KNeighborsRegressor é uma <b>implementação do algoritmo de regressão baseado nos vizinhos mais próximos (k-Nearest Neighbors, k-NN)</b>. O KNN é um algoritmo baseado em instâncias, o que significa que ele faz previsões para novos dados com base nas observações mais próximas no conjunto de treinamento.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42587aa-eec0-4030-8e42-7c41592c4201",
   "metadata": {},
   "source": [
    "*  **n_neighbors:** O número de vizinhos a serem considerados. Um valor menor de k pode captar mais detalhes e levar a um modelo mais complexo (potencialmente overfitting), enquanto um valor maior de k pode resultar em um modelo mais suave (potencialmente underfitting).\n",
    "*  **weights:** Pode ser uniform (todos os vizinhos contribuem igualmente) ou distance (os vizinhos mais próximos têm um peso maior).\n",
    "*  **algorithm:** O algoritmo usado para encontrar os vizinhos mais próximos (auto, ball_tree, kd_tree, brute). O padrão auto tenta escolher o método mais apropriado com base nos dados.\n",
    "*  **metric:** A métrica de distância usada para encontrar os vizinhos. O padrão é a distância Euclidiana.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e452637-011a-4bdb-84d0-bca7a03190f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "#modelKNeighbors = KNeighborsRegressor()\n",
    "modelKNeighbors.fit(X_train,y_train)\n",
    "\n",
    "predictions = modelKNeighbors.predict(X_test)\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "print('R2:', r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32c22d6-360d-4c1c-9f92-4a9708445896",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot((y_test-predictions),bins=50);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b5f091-8e8a-4baa-a6e2-45d100484134",
   "metadata": {},
   "source": [
    "<h2>✅ BayesianRidge</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e404bf-2e79-4291-869e-64fe5a63cf4d",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ffcccc; padding: 20px; border-radius: 10px;\">\n",
    "O BayesianRidge é uma implementação da regressão linear bayesiana, que <b>combina princípios de regressão ridge com <span style=\"color:red\">probabilidade bayesiana</span></b> para fornecer estimativas dos coeficientes de regressão. Assim como a regressão ridge, o BayesianRidge <b>adiciona uma penalização L2 aos coeficientes de regressão, mas faz isso no contexto de uma abordagem bayesiana</b>.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81b0deb-180b-4473-b90f-82c9e7a6ea4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "modelBayesianRidge = BayesianRidge()\n",
    "modelBayesianRidge.fit(X_train,y_train)\n",
    "\n",
    "predictions = modelBayesianRidge.predict(X_test)\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "print('R2:', r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c4963f-98fc-4ca4-8e71-cad23dec828a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot((y_test-predictions),bins=50);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f29650c-b907-474a-9da3-c5517d00b3b4",
   "metadata": {},
   "source": [
    "<h2>✅ MLPRegressor</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471a64a3-ba37-4e84-8d13-26d13b6c78c4",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ffcccc; padding: 20px; border-radius: 10px;\">\n",
    "O MLPRegressor é uma <b>implementação de uma rede neural feedforward (perceptron multicamada) para problemas de regressão</b>. <span style=\"color:red\">É uma rede neural feedforward</span> composta por uma camada de entrada, uma ou mais camadas ocultas e uma camada de saída.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83c92ea-1e53-4c3d-8cbc-5cb2e0683d5f",
   "metadata": {},
   "source": [
    "*  **hidden_layer_sizes** é o número de camadas ocultas e o número de neurônios em cada camada são especificados pelo usuário. \n",
    "*  **activation** diferentes funções de ativação podem ser usadas para os neurônios nas camadas ocultas, como relu (retificação linear), tanh (hiperbólica tangente), logistic (sigmóide), e identity (linear).\n",
    "*  **solver** suporta vários algoritmos de otimização, incluindo adam (um método de otimização estocástica eficiente), sgd (gradiente descendente estocástico) e lbfgs (um otimizador baseado em aproximação quase-Newtoniana).\n",
    "*  **max_iter** número máximo de iterações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dacd86-f6f6-4e3a-9d58-475046b4310f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "#modelMLP = MLPRegressor()\n",
    "modelMLP.fit(X_train,y_train)\n",
    "\n",
    "predictions = modelMLP.predict(X_test)\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "print('R2:', r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c4add9-e541-455d-9302-1481af8995e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot((y_test-predictions),bins=50);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1512c7ce-0429-4008-8ebf-75a184f14688",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ff87b2; padding: 20px; border-radius: 10px;\">\n",
    "<h3>Atividade 3:</h3>\n",
    "\n",
    "Para o estudo de caso do Predição de Cargas de Trabalho para Juízes cujo objetivo prever o volume de trabalho em diferentes tribunais com base em fatores como tamanho da população, tipos de casos comuns na região, etc.\n",
    "\n",
    "Execute os modelos: BayesianRidge, Ridge, RandomForestRegressor, GradientBoostingRegressor, DecisionTreeRegressor, MLPRegressor, SVR, KNeighborsRegressor,Lasso, ElasticNet e LinearRegression+PolynomialFeatures.\n",
    "\n",
    "Monte um DataFrame comparativo mostrando as métricas MAE, MSE, RMSE, R2 de cada modelo.\n",
    "\n",
    "<img src=\"../img/fig4.png\" />\n",
    "\n",
    "Troque o modelo gravado pelo de melhor execução e teste no App Streamlit.\n",
    "\n",
    "Poste no AVA o Jupyter Notebook ou o link para o repositório GitHub.\n",
    "  \n",
    "</div>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4a7aab-a0c6-43fe-85e4-e12f2b22a22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resposta:\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
